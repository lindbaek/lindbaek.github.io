{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f54c68",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Police_Department_Incident_Reports__Historical_2003_to_May_2018_20250208.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolice_Department_Incident_Reports__Historical_2003_to_May_2018_20250208.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlopen\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Police_Department_Incident_Reports__Historical_2003_to_May_2018_20250208.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(\"Police_Department_Incident_Reports__Historical_2003_to_May_2018_20250208.csv\") \n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandata=data.drop(columns=['SF Find Neighborhoods 2 2','Current Police Districts 2 2', 'Current Supervisor Districts 2 2',\n",
    "       'Analysis Neighborhoods 2 2', 'DELETE - Fire Prevention Districts 2 2',\n",
    "       'DELETE - Police Districts 2 2', 'DELETE - Supervisor Districts 2 2',\n",
    "       'DELETE - Zip Codes 2 2', 'DELETE - Neighborhoods 2 2',\n",
    "       'DELETE - 2017 Fix It Zones 2 2',\n",
    "       'Civic Center Harm Reduction Project Boundary 2 2',\n",
    "       'Fix It Zones as of 2017-11-06  2 2', 'DELETE - HSOC Zones 2 2',\n",
    "       'Fix It Zones as of 2018-02-07 2 2',\n",
    "       'CBD, BID and GBD Boundaries as of 2017 2 2',\n",
    "       'Areas of Vulnerability, 2016 2 2',\n",
    "       'Central Market/Tenderloin Boundary 2 2',\n",
    "       'Central Market/Tenderloin Boundary Polygon - Updated 2 2',\n",
    "       'HSOC Zones as of 2018-06-05 2 2', 'OWED Public Spaces 2 2', 'Address',\n",
    "       'Neighborhoods 2', 'PdId'])\n",
    "\n",
    "cleandata['Date'] = pd.to_datetime(cleandata['Date'], format='%m/%d/%Y')\n",
    "\n",
    "crimedata2 = pd.read_csv(\"Police_Department_Incident_Reports__2018_to_Present_20250208.csv\") \n",
    "\n",
    "crimedata2 = crimedata2.replace(['Recovered Vehicle', 'Larceny Theft', 'Lost Property', 'Non-Criminal', 'Drug Violation', 'Assault', 'Malicious Mischief', 'Fraud', 'Warrant', 'Other Offenses', 'Robbery', 'Case Closure', 'Stolen Property','Suspicious Occ', 'Disorderly Conduct', 'Weapons Carrying Etc', 'Rape', 'Drug Offense', 'Missing Person', 'Motor Vehicle Theft', 'Burglary', 'Fire Report', 'Arson', 'Vandalism', 'Suicide', 'Traffic Violation Arrest', 'Forgery And Counterfeiting', 'Sex Offense', 'Prostitution', 'Weapons Offense', 'Miscellaneous Investigation', 'Vehicle Misplaced', 'Suspicious', 'Embezzlement', 'Vehicle Impounded', 'Civil Sidewalks', 'Liquor Laws', 'Gambling', 'Motor Vehicle Theft?', 'Weapons Offence', 'Homicide',  'Other Miscellaneous', 'Other', 'Human Trafficking (A), Commercial Sex Acts', 'Human Trafficking, Commercial Sex Acts', 'Human Trafficking (B), Involuntary Servitude', 'Traffic Collision', 'Courtesy Report', 'Offences Against The Family And Children'], ['RECOVERED VEHICLE','LARCENY/THEFT', 'NON-CRIMINAL', 'NON-CRIMINAL', 'DRUG/NARCOTIC', 'ASSAULT', 'VANDALISM', 'FRAUD', 'WARRANTS', 'OTHER OFFENSES', 'ROBBERY', 'NON-CRIMINAL' , 'STOLEN PROPERTY', 'SUSPICIOUS OCC', 'DISORDERLY CONDUCT', 'WEAPON LAWS', 'SEX OFFENSES, FORCIBLE', 'DRUG/NARCOTIC', 'MISSING PERSON', 'VEHICLE THEFT', 'BURGLARY', 'NON-CRIMINAL', 'ARSON', 'VANDALISM', 'SUICIDE', 'OTHER OFFENSES', 'FORGERY/COUNTERFEITING', 'SEX OFFENSES, NON FORCIBLE', 'PROSTITUTION', 'WEAPON LAWS', 'NON-CRIMINAL', 'NON-CRIMINAL', 'SUSPICIOUS OCC', 'EMBEZZLEMENT', 'SECONDARY CODES', 'DISORDERLY CONDUCT', 'LIQUOR LAWS', 'GAMBLING', 'VEHICLE THEFT', 'WEAPON LAWS', 'ASSAULT', 'SECONDARY CODES', 'SECONDARY CODES', 'SEX OFFENSES, FORCIBLE', 'SEX OFFENSES, FORCIBLE', 'KIDNAPPING', 'NON-CRIMINAL','NON-CRIMINAL', 'OTHER OFFENSES'])\n",
    "\n",
    "crimeCategory = pd.unique(crimedata2[\"Incident Category\"])\n",
    "\n",
    "crimedata2cleaned=crimedata2.drop(columns=['Neighborhoods', 'ESNCAG - Boundary File',\n",
    "       'Central Market/Tenderloin Boundary Polygon - Updated',\n",
    "       'Civic Center Harm Reduction Project Boundary',\n",
    "       'Analysis Neighborhood', 'Supervisor District',\n",
    "       'Supervisor District 2012',      \n",
    "       'HSOC Zones as of 2018-06-05', 'Invest In Neighborhoods (IIN) Areas',\n",
    "       'Current Supervisor Districts', 'Current Police Districts', 'Report Type Code',\n",
    "       'Report Type Description', 'Filed Online', 'Report Datetime', 'CAD Number', 'Incident Subcategory',\n",
    "       'Intersection', 'CNN','Incident Datetime', 'Row ID', 'Incident Year', 'Incident ID'])\n",
    "\n",
    "crimedata2cleaned = crimedata2cleaned.dropna(subset=[\"Incident Category\"])\n",
    "\n",
    "crimedata2cleaned['Incident Date'] = pd.to_datetime(crimedata2cleaned['Incident Date'], format='%Y/%m/%d')\n",
    "\n",
    "crimedata2cleaned = crimedata2cleaned.iloc[:, [3, 4, 5, 6, 2, 0, 1, 8, 7, 10, 9, 11,]]    \n",
    "\n",
    "crimedata2cleaned = crimedata2cleaned[crimedata2cleaned['Incident Date'].dt.year != 2025]\n",
    "\n",
    "crimedata2cleaned = crimedata2cleaned.rename(columns={\"Incident Number\": \"IncidntNum\", \"Incident Code\": \"Incident Code\", \"Incident Category\": \"Category\", \"Incident Description\": \"Descript\", \"Incident Day of Week\": \"DayOfWeek\", \"Incident Date\": \"Date\", \"Incident Time\": \"Time\", \"Police District\": \"PdDistrict\", \"Resolution\": \"Resolution\", \"Longitude\": \"X\", \"Latitude\": \"Y\", \"Point\": \"location\"})\n",
    "\n",
    "allcrime = pd.concat([cleandata, crimedata2cleaned], ignore_index=True)\n",
    "\n",
    "focuscrimes = set(['WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', 'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'])\n",
    "\n",
    "allcrimeCategory = pd.unique(allcrime[\"Category\"])\n",
    "focuscrimes = np.array(list(focuscrimes))\n",
    "\n",
    "boolstuff = ~np.isin(allcrimeCategory, focuscrimes)\n",
    "catToToss = allcrimeCategory[boolstuff]\n",
    "allFocuscrimes = allcrime[~allcrime['Category'].isin(catToToss)]\n",
    "allFocuscrimes=allFocuscrimes.drop(columns=['Descript'])\n",
    "allFocuscrimes['Time_real'] = pd.to_datetime(allFocuscrimes['Time'], format='%H:%M')\n",
    "allFocuscrimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drugs = allFocuscrimes[allFocuscrimes[\"Category\"] == \"DRUG/NARCOTIC\"]\n",
    "df_drugs = df_drugs.dropna()\n",
    "df_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38255c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 37.828724\n",
    "lon = -122.355537\n",
    "\n",
    "map_drugs = folium.Map([lat, lon], zoom_start=12)\n",
    "heat_df = df_drugs[['Y', 'X']]\n",
    "heat_data = [[row['Y'],row['X']] for index, row in heat_df.iterrows()]\n",
    "\n",
    "# Plot it on the map\n",
    "HeatMap(heat_data).add_to(map_drugs)\n",
    "\n",
    "# Display the map\n",
    "map_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa2d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drugs[\"Date\"] = pd.to_datetime(df_drugs[\"Date\"])\n",
    "df_drugs[\"year\"] = df_drugs[\"Date\"].dt.year\n",
    "df_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ee11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 37.776669\n",
    "lon = -122.452708\n",
    "map_drugs_time = folium.Map([lat, lon], zoom_start=12)\n",
    "\n",
    "heat_df = df_drugs.loc[:, ['Y', 'X']]\n",
    "\n",
    "# Create weight column, using date\n",
    "heat_df.loc[:,'Weight'] = df_drugs['year']\n",
    "heat_df = heat_df.dropna(axis=0, subset=['Y','X', 'Weight'])\n",
    "\n",
    "# List comprehension to make out list of lists\n",
    "heat_data = [[[row['Y'],row['X']] for index, row in heat_df[heat_df['Weight'] == i].iterrows()] for i in range(2003,2024)]\n",
    "\n",
    "# Parameters\n",
    "hm = plugins.HeatMapWithTime(\n",
    "    heat_data,\n",
    "    index=list(range(2003, 2024)),  # Explicitly set years as time labels\n",
    "    auto_play=True,\n",
    "    max_opacity=0.8,\n",
    "    radius=10,\n",
    "    blur=0.5,\n",
    "    position=\"bottomright\"\n",
    ")\n",
    "hm.add_to(map_drugs_time)\n",
    "\n",
    "\n",
    "# Add heat map to the Folium map\n",
    "hm.add_to(map_drugs_time)\n",
    "\n",
    "# Display the map\n",
    "map_drugs_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e495bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_drugs_time.save(\"heatmapdrugs.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f6e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
